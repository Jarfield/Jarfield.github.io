<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><title>分类: 阅读笔记 - Jarfield&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f7f7f7"><meta name="application-name" content="Jarfield&#039;s Blog"><meta name="msapplication-TileImage" content="/images/favicon.svg"><meta name="msapplication-TileColor" content="#f7f7f7"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jarfield&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="一些学习笔记分享"><meta property="og:type" content="blog"><meta property="og:title" content="Jarfield&#039;s Blog"><meta property="og:url" content="https://jarfield.github.io/"><meta property="og:site_name" content="Jarfield&#039;s Blog"><meta property="og:description" content="一些学习笔记分享"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://jarfield.github.io/img/og_image.png"><meta property="article:author" content="JArfield"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://jarfield.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://Jarfield.github.io"},"headline":"Jarfield's Blog","image":["https://jarfield.github.io/img/og_image.png"],"author":{"@type":"Person","name":"JArfield"},"publisher":{"@type":"Organization","name":"Jarfield's Blog","logo":{"@type":"ImageObject","url":"https://jarfield.github.io/images/logo.svg"}},"description":"一些学习笔记分享"}</script><link rel="icon" href="/images/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link data-pjax rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-72437521-5" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-72437521-5');</script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo.svg" alt="Jarfield&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Discuss on GitHub" href="/null"><i class="fas fa-comments"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="/null"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories/">分类</a></li><li class="is-active"><a href="#" aria-current="page">阅读笔记</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/10/26/Notes/MAR_Note/"><img class="fill" src="/images/MAR/dog.jpg" alt="MAR: MEDICAL ASYMMETRIC RETRIEVER FOR EFFICIENT CHINESE MEDICAL DENSE RETRIEVAL 阅读笔记"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2025-10-26T15:10:20.000Z" title="2025/10/26 23:10:20">2025-10-26</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span><span class="level-item">29 分钟读完 (大约4390个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/10/26/Notes/MAR_Note/">MAR: MEDICAL ASYMMETRIC RETRIEVER FOR EFFICIENT CHINESE MEDICAL DENSE RETRIEVAL 阅读笔记</a></p><div class="content"><h1
id="mar-medical-asymmetric-retriever-for-efficient-chinese-medical-dense-retrieval-阅读笔记">MAR:
MEDICAL ASYMMETRIC RETRIEVER FOR EFFICIENT CHINESE MEDICAL DENSE
RETRIEVAL 阅读笔记</h1>
<p><strong>金培晟</strong> <em>Jarfield</em></p>
<h2 id="摘要">0 摘要</h2>
<p>本文提出<strong>中文医学文本嵌入基准
MedTEB</strong>，覆盖三类贴近真实场景的任务：检索、重排序与医学同义句相似度（STS）。在构建过程中，我们采用<strong>基于多模型的
LLM 标注流程</strong>以提升数据质量。对强通用嵌入模型在 MedTEB
上的评测显示，该基准具有<strong>面向领域且更具挑战性</strong>的检索评测价值。基于此，我们提出<strong>医学非对称检索器（MAR）</strong>：将查询与文档编码解耦，在线用<strong>轻量查询编码器</strong>实现低延迟，离线用<strong>更强大的（LLM-based）文档编码器</strong>保证检索质量。为优化这一非对称架构，我们引入<strong>两阶段训练框架</strong>：（1）查询编码器对齐；（2）
联合微调。实验表明，MAR 在 MedTEB 上取得<strong>SOTA
性能</strong>，同时其推理速度与<strong>小型 BERT
类嵌入模型</strong>相当，兼顾<strong>准确率与效率</strong>，适用于真实的中文医学检索场景。代码、数据与模型将公开以促进后续研究。</p>
<h2 id="引言">1 引言</h2>
<ol type="1">
<li><p><strong>背景与动机</strong></p>
<ul>
<li><p>向量表征（embedding）是现代 NLP
的基础，广泛用于检索、重排、分类，并是 RAG 的关键组件。</p></li>
<li><p>医疗等专门领域中，LLM
往往缺乏深度专家知识；因此需要<strong>准确且低延迟</strong>地访问医学知识，以提升临床决策支持并减少
RAG 幻觉：<strong>领域化、低延迟的医学嵌入是刚需</strong>。</p></li>
</ul></li>
<li><p><strong>现状与差距</strong></p>
<ul>
<li><p>通用嵌入模型进展很快，但<strong>中文医学文本嵌入关注不足</strong>。</p></li>
<li><p>现有基准如 C-MTEB
仅含两套中文医学检索数据，且存在<strong>标注噪声与假负例</strong>。</p></li>
<li><p>当前强力嵌入多为<strong>LLM-based</strong>：性能强但<strong>延迟与算力成本高</strong>，限制实时医疗问答等敏感场景。</p></li>
</ul></li>
<li><p><strong>基准贡献（MedTEB）</strong></p>
<ul>
<li><p><strong>MedTEB</strong>：包含<strong>检索、重排序、医学同义句
STS</strong>三类全新整理任务，并纳入两套公开数据。</p></li>
<li><p>使用<strong>LLM 驱动的标注流程</strong>提升标签质量。</p></li>
<li><p>评测显示：即便强大的通用嵌入模型在 MedTEB
上表现也不佳，证明其<strong>难度与领域针对性</strong>。</p></li>
</ul></li>
<li><p><strong>方法贡献（MAR 非对称检索器 + 两阶段训练）</strong></p>
<ul>
<li><p><strong>MAR</strong>：<strong>轻量查询编码器</strong>在线服务以降延迟，<strong>更强文档编码器</strong>离线建库保性能。</p></li>
<li><p><strong>两阶段优化</strong>：（1）查询编码器对齐；（2）联合微调，直接面向检索目标。</p></li>
<li><p><strong>结果</strong>：如<code>Figure1</code>所示：</p>
<p><img src="/images/MAR/Figure1.png" alt="image-20251026161810384" style="zoom:33%;" /></p></li>
</ul></li>
</ol>
<h2 id="相关工作">2 相关工作</h2>
<ol type="1">
<li><p><strong>Embedding Models</strong></p>
<ul>
<li><p><strong>发展过程</strong>：从无监督对比预训练（如
Contriever）到大规模指令化/对比预训练（E5、GTE、BGE），通用语义表示显著提升。</p></li>
<li><p><strong>Decoder-only
兴起</strong>：Qwen3-Embedding、bge-en-icl、NV-Embed 等在 MTEB 上达
SOTA，证明仅解码器架构也能产出强嵌入。</p></li>
<li><p><strong>瓶颈</strong>：多数 LLM-based
模型<strong>参数量大、延迟高、开销重</strong>，不适合实时医疗检索等<strong>延迟敏感</strong>场景：需要<strong>轻量且有效</strong>的领域嵌入。</p></li>
</ul></li>
<li><p><strong>Medical Embedding Benchmarks</strong></p>
<ul>
<li><p>MTEB 提供跨语种多任务评测；C-MTEB 纳入多项中文数据集。</p></li>
<li><p>已有医学相关数据（CmedqaRetrieval、MedicalRetrieval、CMedQA-v1/v2
等）虽被收录，但<strong>检索</strong>任务存在<strong>标注噪声与假负例</strong>，相对仅<strong>重排序</strong>更可靠。</p></li>
<li><p>缺少<strong>系统化、可信度高</strong>的中文医学嵌入基准
：<strong>MedTEB</strong> 即为弥补此缺口。</p></li>
</ul></li>
<li><p><strong>Asymmetric Architecture</strong></p>
<ul>
<li><strong>两大路线</strong>：
<ol type="1">
<li><strong>裁剪+蒸馏</strong>：如
KALE，从大编码器裁剪层得到<strong>轻量查询塔</strong>，用 <strong>L2/KL
等对齐损失</strong>蒸馏教师知识；</li>
<li><strong>异构编码器</strong>：如
ScalingNote、HotelMatch，<strong>查询/文档用不同架构或模态</strong>，通过对齐学习提升检索效果。</li>
</ol></li>
<li><strong>本文不同做法</strong>：
<ol type="1">
<li><strong>文档塔用 decoder-only</strong>，天然适配异构对齐；</li>
<li>提出<strong>两阶段对齐框架</strong>（查询对齐+联合微调），直接面向检索优化；</li>
<li><strong>不做高维投影</strong>：保持原始低维、检索更高效。</li>
</ol></li>
</ul></li>
</ol>
<h2 id="medteb">3 MEDTEB</h2>
<ol type="1">
<li><p>中文医学嵌入基准稀缺；现有 CmedqaRetrieval、MedicalRetrieval
多源自<strong>问答配对</strong>，忽略跨样本的潜在相关答案，医学领域“<strong>主题强度</strong>”又放大了<strong>假阴性</strong>风险。</p>
<blockquote>
<p>在问答配对式数据中，<strong>假阴性</strong>就是：本应相关的答案被标成负例，模型检索对了却被评测判错。医学场景尤甚——同一疾病/药物常有大量可通用的专业回答，配对之外的有效答案在标注里被遗漏而默认为负。例：查询“莫西沙星能和布洛芬一起吃吗？”标注只认
A 医生为正，把 B/C
医生在其他贴里给出的同样正确用药原则都记作负；模型检到 B/C
仍被判错。</p>
</blockquote></li>
<li><p><strong>实验依据</strong>：LLM 预标注显示——MedicalRetrieval
每条查询平均 <strong>8.6</strong>
个“被标负但可能相关”的候选；CmedqaRetrieval 约 <strong>19</strong>
个。</p></li>
<li><p><strong>MedTEB</strong>：三项<strong>新任务</strong>（Retrieval /
Reranking / Synonym STS）+
两个<strong>人工核验</strong>公开数据（CMedQA-v1/-v2-reranking）。</p></li>
</ol>
<h3 id="construction-method">3.1 CONSTRUCTION METHOD</h3>
<ul>
<li><strong>Retrieval</strong>：
<ul>
<li><strong>多检索器召回 + 多 LLM 共识标注</strong>；数据为 <span
class="math inline"><em>Q</em></span>（真实匿名查询）、<span
class="math inline"><em>D</em><sup>′</sup> ⊆ <em>D</em></span>（标注后语料）、<span
class="math inline"><em>R</em> = {(<em>q</em><sub><em>i</em></sub>, <em>d</em><sub><em>j</em></sub>, <em>y</em><sub><em>i</em><em>j</em></sub>)|<em>y</em><sub><em>i</em><em>j</em></sub> ∈ {0, 1}}</span>。</li>
<li>与 AIR-Bench 做法的区别：<strong>(i) 医疗域</strong>、<strong>(ii)
真实查询</strong>、<strong>(iii) 多 LLM +
大候选池</strong>缓解误标负与未标注正。</li>
</ul></li>
<li><strong>Rerank</strong>：
<ul>
<li>同样用多 LLM 标注，得正集 <span
class="math inline"><em>P</em><sub><em>i</em></sub></span>、负集 <span
class="math inline"><em>N</em><sub><em>i</em></sub></span>；构造三元组
<span
class="math inline">(<em>q</em><sub><em>i</em></sub>, <em>P</em><sub><em>i</em></sub><sup>list</sup>, <em>N</em><sub><em>i</em></sub><sup>list</sup>)</span>。</li>
</ul></li>
<li><strong>STS</strong>：
<ul>
<li>先建<strong>医学同义词词表</strong>；对每个 <span
class="math inline"><em>q</em><sub><em>i</em></sub></span>，GPT-4o
生成：<span
class="math inline"><em>s</em><sub><em>i</em></sub><sup>+</sup></span>（同义保义）、<span
class="math inline"><em>s</em><sub><em>i</em>, 1</sub><sup>−</sup></span>（同义改义）、<span
class="math inline"><em>s</em><sub><em>i</em>, 2</sub><sup>−</sup></span>（非同义改义）。</li>
<li>采样<span
class="math inline"><em>s</em><sub><em>i</em></sub> ∈ {<em>s</em><sub><em>i</em></sub><sup>+</sup>, <em>s</em><sub><em>i</em>, 1</sub><sup>−</sup>, <em>s</em><sub><em>i</em>, 2</sub><sup>−</sup>}</span>配对成
<span
class="math inline">(<em>q</em><sub><em>i</em></sub>, <em>s</em><sub><em>i</em></sub>, <em>y</em><sub><em>i</em></sub>)</span>，检验<strong>细粒度同义理解</strong>。</li>
</ul></li>
</ul>
<h3 id="evaluation-of-existing-embedding-models">3.2 EVALUATION OF
EXISTING EMBEDDING MODELS</h3>
<ul>
<li><p><strong>数据规模（Table 1）</strong>：</p>
<p><img src="/images/MAR/Table1.png" alt="image-20251026170312950" style="zoom: 67%;" /></p></li>
<li><p><strong>关键发现（Table 2）</strong>：</p>
<ul>
<li>通用嵌入在 CMedQA 与新任务：<strong>85.15</strong> vs
<strong>57.85</strong>：新任务更具挑战、医学域欠发达。</li>
<li><strong>Spearman ρ=0.354,
p=0.215</strong>（≫0.05）：<strong>新任务非冗余</strong>，能从新视角评估模型。</li>
<li><strong>decoder-only</strong> 模型，如
<strong>Qwen3-Embedding-8B</strong> 在新任务平均
<strong>64.52</strong>；但<strong>延迟与算力成本高</strong>，限制真实应用。</li>
</ul>
<p><img src="/images/MAR/Table2.png" alt="image-20251026170510938" style="zoom:67%;" /></p></li>
</ul>
<h2 id="medical-asymmetric-retriever">4 MEDICAL ASYMMETRIC
RETRIEVER</h2>
<p>鉴于现有模型在 MedTEB 上的局限性，作者提出<strong>非对称嵌入架构 +
两阶段训练</strong>：离线用更强的<strong>文档编码器</strong>（Doc
Encoder）对全量语料向量化并建库；在线仅用<strong>轻量查询编码器</strong>（Query
Encoder）编码用户查询进行近似向量检索。</p>
<figure>
<img src="/images/MAR/Figure2.png" alt="image-20251026221506915" />
<figcaption aria-hidden="true">image-20251026221506915</figcaption>
</figure>
<h3 id="high-quality-data-construction">4.1 HIGH-QUALITY DATA
CONSTRUCTION</h3>
<ol type="1">
<li><p><strong>难点</strong>：医学“主题强度”导致<strong>潜在正样本多</strong>，传统
hard negative 工作流程常失效：</p>
<ul>
<li><p><strong>Top-k
挖负</strong>易夹带<strong>假阴性</strong>（未标注但相关的文档）；</p></li>
<li><p><strong>阈值过滤</strong>决策边界模糊；</p></li>
<li><p>对庞大候选池做<strong>全量 LLM 标注</strong>成本过高。</p></li>
</ul></li>
<li><p><strong>多样性感知三步管线</strong>：</p>
<figure>
<img src="/images/MAR/Figure3.png" alt="image-20251026221621738" />
<figcaption aria-hidden="true">image-20251026221621738</figcaption>
</figure>
<ol type="1">
<li><strong>清洗与匿名化</strong>：从公开资源汇集中文医学语料 <span
class="math inline"><em>D</em></span>，并从线上服务收集<strong>真实匿名查询</strong>
<span
class="math inline"><em>Q</em></span>；去隐私、正则清洗、格式规范化。</li>
<li><strong>去重与多样化</strong>：基于<strong>动态向量索引</strong>（先建索引、再以相似度阈值过滤）去语义近重复，并按主题做均衡采样，降低冗余、提升长尾覆盖。</li>
<li><strong>候选内精标</strong>：对每个 <span
class="math inline"><em>q</em></span>
由<strong>多检索器融合</strong>召回 <strong>Top-50</strong> 候选，再用
<strong>GPT-4o</strong>（多 LLM
共识）标注<strong>可靠正/负</strong>，最终产出约 <strong>50 万</strong>
检索三元组 <span
class="math inline">(<em>q</em>, <em>d</em><sup>+</sup>, <em>d</em><sup>−</sup>)</span>。</li>
</ol></li>
<li><p><strong>自对齐数据</strong>（服务于非对称对齐）：</p>
<ul>
<li><p><strong>查询侧</strong>：<span
class="math inline">(<em>q</em>, <em>q</em>, <em>q</em><sup>−</sup>)</span>
共 <strong>2.8M</strong>；</p></li>
<li><p><strong>文档侧</strong>：<span
class="math inline">(<em>d</em>, <em>d</em>, <em>d</em><sup>−</sup>)</span>
共 <strong>5.6M</strong>；</p></li>
</ul>
<blockquote>
<p>其中正样由“文本与自身”构造，负样采用<strong>批内负</strong>为主。</p>
</blockquote></li>
</ol>
<h3 id="independent-initialization">4.2 INDEPENDENT INITIALIZATION</h3>
<p>为给两塔注入<strong>领域知识</strong>并提供稳健起点，先训练一个<strong>对称双塔</strong>（Query
= Doc 结构一致）：</p>
<ol type="1">
<li><strong>查询编码器（三级预训练 → 监督微调）</strong>
<ul>
<li><strong>RetroMAE
预训练</strong>：编码器/轻量解码器<strong>异步掩码</strong>；编码器产出句向量，解码器做
MLM 重构。语料：<strong>6000
万条</strong>中文<strong>医疗问答</strong>无监督语料。</li>
<li><strong>无监督 InfoNCE 预训练</strong>：损失为 InfoNCE（温度
<strong>τ 可学习</strong>）。将<strong>标题–正文</strong>视作正对 <span
class="math inline">(<em>q</em>, <em>d</em><sup>+</sup>)</span>，同
batch 其余样本作<strong>批内负</strong>。</li>
<li><strong>有监督 InfoNCE 微调</strong>：在 §4 构建的高质量数据 +
<strong>MedTEB 训练划分</strong>（Retrieval、Rerank、<strong>CMedQA
v1/v2</strong>、<strong>Synonym STS</strong>）上，用 InfoNCE
端到端优化检索表征。</li>
</ul></li>
<li><strong>文档编码器（大模型微调 + 多维嵌入）</strong>
<ul>
<li><strong>LoRA 微调</strong>：以 <strong>Qwen3-4B / Qwen3-8B</strong>
为底座，<strong>rank=32，α=64</strong>，在控制算力的同时保持性能。</li>
<li><strong>MRL（Matryoshka Representation
Learning）</strong>：训练<strong>嵌套维度集合 <span
class="math inline"><em>M</em></span></strong>，在每个目标维度上各自计算
InfoNCE，并<strong>对所有维度的损失求平均</strong>。推理时可<strong>截断到前
m
维</strong>以匹配轻量查询塔的向量维度，兼顾<strong>精度/延迟/索引大小</strong>的部署弹性。</li>
</ul></li>
</ol>
<blockquote>
<p>初始化后得到一个<strong>性能稳健的对称表示空间</strong>，为后续的<strong>非对称对齐（Stage
I）</strong>与<strong>联合微调（Stage II）</strong>打下基础。</p>
</blockquote>
<h3 id="asymmetric-embedding-architecture">4.3 ASYMMETRIC EMBEDDING
ARCHITECTURE</h3>
<ol type="1">
<li><strong>范式</strong>：</li>
</ol>
<ul>
<li><p><strong>离线</strong>：Doc Encoder
对全集语料向量化，构建<strong>向量索引</strong>（可用余弦/内积）；</p></li>
<li><p><strong>在线</strong>：Query Encoder 编码用户查询，进行 ANN
检索（HNSW/FAISS 等实现可替换）。</p></li>
</ul>
<ol start="2" type="1">
<li><strong>难点</strong>：轻量查询塔与强力文档塔<strong>嵌入空间天然不对齐</strong>。</li>
</ol>
<h4 id="asymmetric-stage-i-query-encoder-alignment">4.3.1 ASYMMETRIC
STAGE I: QUERY ENCODER ALIGNMENT</h4>
<ol type="1">
<li><p><strong>做法</strong>：冻结 Doc
Encoder（<strong>教师</strong>），仅更新 Query
Encoder（<strong>学生</strong>）。训练数据采用上节的<strong>自对齐集合</strong>与检索候选池中的正/负。</p></li>
<li><p><strong>目标函数（混合对齐）</strong>： <span
class="math display">$$
\frac{a}{b}
$$</span></p>
<ol type="1">
<li><strong>Asym-InfoNCE（相对排序对齐）</strong></li>
</ol>
<p><span class="math display">$$
\mathcal{L}_{\text{Asym}}
= -\log \frac{\exp(s^+/\tau)}
{\exp(s^+/\tau) + \sum_{i=1}^{N}\exp(s_i^-/\tau)}
$$</span></p>
<blockquote>
<p>其中 <span
class="math inline"><em>s</em><sup>+</sup> = sim(<em>E</em><sub><em>Q</em></sub>(<em>q</em>), <em>E</em><sub><em>D</em></sub>(<em>d</em><sup>+</sup>))</span>,
<span
class="math inline"><em>s</em><sub><em>i</em></sub><sup>−</sup> = sim(<em>E</em><sub><em>Q</em></sub>(<em>q</em>), <em>E</em><sub><em>D</em></sub>(<em>d</em><sub><em>i</em></sub><sup>−</sup>))</span>，<span
class="math inline">sim</span>
为<strong>余弦相似</strong>（向量已归一化）， <span
class="math inline"><em>τ</em></span> 为温度，<span
class="math inline"><em>N</em></span>
为负样数量（批内负为主）。在自对齐样本上，<span
class="math inline"><em>q</em></span> 与 <span
class="math inline"><em>d</em><sup>+</sup></span>
为<strong>同一文本</strong>，可稳定拉近两塔同源表示。</p>
</blockquote>
<ol start="2" type="1">
<li><strong>MSE（绝对位置对齐）</strong></li>
</ol>
<p><span
class="math display">ℒ<sub>MSE</sub> = ∥ <em>E</em><sub><em>Q</em></sub>(text) − <em>E</em><sub><em>D</em></sub>(text) ∥<sub>2</sub><sup>2</sup>,</span></p>
<blockquote>
<p>直接惩罚同一文本在两塔中的向量距离，补充“坐标级”的对齐约束。</p>
</blockquote>
<ol start="3" type="1">
<li><strong>联合损失</strong></li>
</ol>
<p><span class="math display">ℒ<sub>Stage
I</sub> = <em>λ</em><sub>1</sub>ℒ<sub>Asym</sub> + <em>λ</em><sub>2</sub>ℒ<sub>MSE</sub>,  <em>λ</em><sub>1</sub> = <em>λ</em><sub>2</sub> = 1.</span></p></li>
<li><p><strong>直觉</strong>：Asym-InfoNCE
提供<strong>相对排序</strong>信号，MSE
提供<strong>绝对位置</strong>信号；两者协同可更稳地缩小两塔语义鸿沟，避免仅有排序信号时的漂移。</p></li>
</ol>
<h3 id="asymmetric-stage-ii-joint-fine-tuning">4.4 ASYMMETRIC STAGE II:
JOINT FINE-TUNING</h3>
<ol type="1">
<li><strong>目标</strong>：在初步对齐的基础上，<strong>端到端</strong>提升检索判别力。</li>
<li><strong>做法</strong>：解冻两塔，仅以 <strong>Asym-InfoNCE</strong>
为训练目标；结合<strong>批内负 + 硬负</strong>丰富难例。</li>
<li><strong>结果</strong>：最终得到 <strong>MAR</strong>（Medical
Asymmetric Retriever）系列模型——在 MedTEB
上取得强精度，同时<strong>在线仅跑轻量查询塔</strong>、<strong>离线预计算文档塔</strong>，实现<strong>SOTA
级准确率 × 小模型级 QPS/延迟</strong>的现实可用折中。</li>
</ol>
<h2 id="实验">5 实验</h2>
<h3 id="setup">5.1 SETUP</h3>
<ol type="1">
<li><strong>Models</strong>
<ul>
<li><strong>Query</strong>：<em>Medical-Embedder-base</em>（由
<strong>gte-multilingual-mlm-base</strong> 初始化，≈0.3B 参数）。</li>
<li><strong>Document</strong>：<em>Medical-Embedder-4B / -8B</em>（在
<strong>Qwen3-4B / Qwen3-8B</strong> 上微调）。</li>
<li><strong>Asymmetric 变体</strong>：<strong>MAR-0.3B-4B</strong>（0.3B
Query + 4B Doc）、<strong>MAR-0.3B-8B</strong>（0.3B Query + 8B
Doc）。</li>
<li><strong>Baselines</strong>：BGE、GTE、Qwen3-Embedding、Conan-embedding-v1、stella-base-zh-v3-1792d
等。</li>
</ul></li>
<li><strong>Training Data（统一）</strong> 第4节的高质量微调集 +
<strong>MedTEB 训练划分</strong>（Retrieval / Rerank / CMedQA / Synonym
STS）。即便部分baseline在预训练阶段见过
CMedQA，仍<strong>显式纳入</strong>以避免该任务潜在性能下降。</li>
<li><strong>Implementation</strong>
<ul>
<li><strong>检索评估</strong>：用 <strong>FAISS</strong> 近邻检索。</li>
<li><strong>总exposure量对齐</strong>：所有对称基线 <strong>fine-tune 2
个
epoch</strong>，与本文提出的<strong>MAR</strong>总exposure量匹配。</li>
<li>计算资源：<strong>32× A100-40GB</strong>。</li>
</ul></li>
</ol>
<h3 id="main-results-on-medteb">5.2 MAIN RESULTS ON MEDTEB</h3>
<p><img src="/images/MAR/Table3.png" alt="image-20251026224702910" style="zoom:67%;" /></p>
<ol type="1">
<li><strong>SOTA</strong>：
<ul>
<li><strong>MAR-0.3B-4B</strong> 平均
<strong>78.13</strong>，<strong>MAR-0.3B-8B</strong> 平均
<strong>78.94</strong>；均<strong>超过</strong>最强基线
<strong>gte-Qwen2-1.5B-instruct </strong>=
<strong>77.61</strong>（decoder-only），且<strong>Query 仅
0.3B</strong>。</li>
</ul></li>
<li><strong>扩展性</strong>：
<ul>
<li>将文档塔 <strong>4B → 8B</strong>，平均提升
<strong>+0.81</strong>；<strong>查询时延不变</strong>（Query 仍
0.3B）。</li>
</ul></li>
</ol>
<hr />
<h3 id="asymmetric-vs.-symmetric">5.3 ASYMMETRIC vs. SYMMETRIC</h3>
<p><img src="/images/MAR/Table4.png" alt="image-20251026225038268" style="zoom: 67%;" /></p>
<blockquote>
<p>非对称方案<strong>逼近</strong>大文档模型的上限（8B 对称 65.63 vs. 8B
非对称 65.21)，同时远超轻量对称；<strong>放大 Doc
塔</strong>能<strong>单向提升</strong>精度，且<strong>不增加查询时延</strong>。</p>
</blockquote>
<h3 id="ablation-study">5.4 ABLATION STUDY</h3>
<h4 id="training-design">5.4.1 Training Design</h4>
<p><img src="/images/MAR/Table5.png" alt="image-20251026225211692" style="zoom: 67%;" /></p>
<ol type="1">
<li><p><strong>独立初始化缺一不可</strong>：去掉 Query init →
<strong>59.66</strong>；去掉 Doc init → <strong>50.26</strong>；完整模型
<strong>64.38</strong>。</p>
<blockquote>
<p>先训<strong>对称双塔</strong>为非对称阶段提供<strong>更强起点</strong>至关重要。</p>
</blockquote></li>
<li><p><strong>两阶段都重要</strong>：无 Query 对齐 →
<strong>51.07</strong>；无联合微调 → <strong>55.49</strong>；完整
<strong>64.38</strong>。</p>
<blockquote>
<p><strong>对齐阶段</strong>让学生 Query 学到教师 Doc
的空间，<strong>联合微调</strong>让两塔适配下游检索。</p>
</blockquote></li>
<li><p><strong>损失设计（Stage I）</strong>：去 <strong>MSE</strong> →
<strong>63.57</strong>；去<strong>对比项</strong> →
<strong>64.03</strong>；两者并用 <strong>64.38（最佳）</strong>。</p>
<blockquote>
<p><strong>相对排序（Asym-InfoNCE）+
绝对位置（MSE）</strong>均有贡献。</p>
</blockquote></li>
</ol>
<h4 id="query-alignment-data">5.4.2 Query Alignment Data</h4>
<p><img src="/images/MAR/Table6.png" alt="image-20251026225406136" style="zoom:67%;" /></p>
<ol type="1">
<li><strong>仅做 Stage-I</strong>：用“fine-tuning
数据”<strong>57.26</strong> &gt; “alignment
数据”<strong>55.49</strong>。</li>
<li><strong>再接 Stage-II</strong>：先用 alignment 数据的最终表现
<strong>64.38</strong> &gt; 先用 fine-tuning 数据
<strong>60.49</strong>。</li>
</ol>
<blockquote>
<p><strong>对齐专用数据</strong>更能<strong>铺好表示空间</strong>、<strong>抬高性能上限</strong>；直接用下游数据做对齐易<strong>过早收敛</strong>、表达不佳。</p>
</blockquote>
<h4 id="alternatives-to-efficient-retrieval">5.4.3 Alternatives to
Efficient Retrieval</h4>
<p><img src="/images/MAR/Table7.png" alt="image-20251026225516869" style="zoom:67%;" /></p>
<ol type="1">
<li><strong>KALE</strong>：<strong>55.05</strong>；<strong>Wang &amp;
Lyu
(2023)</strong>：<strong>53.13</strong>；<strong>ScalingNote</strong>：<strong>49.49</strong>（均为非对称）。</li>
<li><strong>Distill-from-4B（对称蒸馏学生）</strong>：<strong>62.72</strong>。</li>
<li><strong>MAR-0.3B-4B</strong>：<strong>64.38（最佳）</strong>。</li>
</ol>
<blockquote>
<p>编码器裁剪/分数蒸馏在<strong>decoder-only</strong>场景下适配有限；<strong>直接把强
Doc
作为教师并保留其离线向量</strong>，可避免蒸馏信息损失，检索效果更强。</p>
</blockquote>
<h2 id="结论">6 结论</h2>
<p>本文发布中文医学嵌入新基准
<strong>MedTEB</strong>，并提出面向<strong>低延迟医疗检索</strong>的非对称模型
<strong>MAR</strong>（轻量查询侧 + 大规模文档侧，二阶段对齐/微调）。在
MedTEB 上取得
<strong>SOTA</strong>，并开源<strong>基准、模型与训练流程</strong>，为真实医疗
RAG 落地与领域嵌入研究提供实践方案与起点。</p>
<h2 id="我的思考">我的思考</h2>
<p>读完这篇论文，我学习到了一条可落地的路线：<strong>把“强能力”放在离线的文档塔，把“低时延”放在在线的查询塔</strong>。这种非对称设计天然适配需要实时响应的检索/RAG；迁移到多模态时，也只需把文档塔换成强
VLM/MLLM，查询侧保留轻量编码头即可。</p>
<p>同时，本文的<strong>训练策略</strong>也很关键：先做一次<strong>对称初始化</strong>给两塔注入领域知识；随后
<strong>Stage-I</strong> 冻结文档塔，只训查询塔，用
<strong>Asym-InfoNCE（相对排序）+
MSE（绝对位置）</strong>把两塔空间拉齐；最后 <strong>Stage-II</strong>
解冻两塔，仅用 Asym-InfoNCE
面向检索目标端到端优化。这里的一个小技巧值得照搬——<strong>对齐专用数据</strong>：<span
class="math inline">(<em>q</em>, <em>q</em>, <em>q</em><sup>−</sup>)</span>/<span
class="math inline">(<em>d</em>, <em>d</em>, <em>d</em><sup>−</sup>)</span>
先把“同一文本”在两塔里对齐到同一位置，再去学正负间隔；而文档塔用
<strong>LoRA</strong> 降算力、配合 <strong>MRL</strong>
训练多维嵌套表示，后续就能在不改查询塔的前提下，<strong>只放大文档塔</strong>来换取精度，查询时延几乎不变。</p>
<p>数据层面，我明白高质量数据的价值，通过<strong>在 Top-K
候选里精做数据</strong>——多检索器召回→多 LLM
一致性复核→必要时允许<strong>多正样</strong>
的做法，专门对付医学场景里“主题强度高导致假阴性多”的难点。做多模态时，同样可以考虑把一致性扩展成
<strong>VLM+LLM</strong> 双通道。</p>
<p>最后是<strong>如何从实验结果中分析</strong>：一方面，针对<strong>精度&amp;效率双线</strong>（nDCG@10/Recall@k
+
QPS/显存/延迟），探究“文档塔变大、查询时延不变”的收益；另一方面，通过<strong>轻量诊断</strong>——假阴性（每查询的可疑负例数+抽检通过率）、错误切片（实体/同义/否定等维度），以及对齐前后<strong>余弦相似度</strong>确认空间收敛。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2025-10-08T15:36:20.000Z" title="2025/10/8 23:36:20">2025-10-08</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span><span class="level-item">1 分钟读完 (大约213个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/10/08/Notes/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/">大语言模型（阅读笔记1）</a></p><div class="content"><h1 id="大语言模型阅读笔记1">大语言模型（阅读笔记1）</h1>
<h2 id="第一章-引言">第一章 引言</h2>
<h3 id="语言模型的发展历程">1.1 语言模型的发展历程</h3>
<p>语言模型的发展大致分为四个阶段：<strong>统计语言模型</strong>解决了最初的词序预测问题，但受限于稀疏性与维度灾难；<strong>神经语言模型</strong>引入词嵌入，改进语义表征；<strong>预训练模型</strong>（如
BERT、GPT-1）借助大规模无监督学习与微调，提升了上下文理解；最终演进到<strong>大语言模型</strong>（如
GPT-3/4），通过规模扩展展现出“涌现能力”。 这里最关键的转折点是
Transformer 的提出，它既解决了长程依赖问题，又适配了并行计算，为后续 LLM
奠定了基础。</p>
<h3 id="大语言模型的能力特点">1.2 大语言模型的能力特点</h3>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/images/avatar/avatar.jpg" alt="Jarfield"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jarfield</p><p class="is-size-6 is-block">Web Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>AnHui, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives/"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories/"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags/"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Jarfield" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Jarfield"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Facebook" href="/null"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Twitter" href="/null"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Dribbble" href="/null"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">阅读笔记</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-10-26T15:10:20.000Z">2025-10-26</time></p><p class="title"><a href="/2025/10/26/Notes/MAR_Note/">MAR: MEDICAL ASYMMETRIC RETRIEVER FOR EFFICIENT CHINESE MEDICAL DENSE RETRIEVAL 阅读笔记</a></p><p class="categories"><a href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-10-08T15:36:20.000Z">2025-10-08</time></p><p class="title"><a href="/2025/10/08/Notes/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%951/">大语言模型（阅读笔记1）</a></p><p class="categories"><a href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-07-09T06:36:20.000Z">2025-07-09</time></p><p class="title"><a href="/2025/07/09/a-lovely-dog/">a lovely dog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-12-02T10:16:55.675Z">2024-12-02</time></p><p class="title"><a href="/2024/12/02/hello-world/">Hello World</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/10/"><span class="level-start"><span class="level-item">十月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/07/"><span class="level-start"><span class="level-item">七月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><span class="tag">大语言模型</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%B4%BB/"><span class="tag">生活</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/"><span class="tag">知识蒸馏</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/"><span class="tag">科研学习</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo.svg" alt="Jarfield&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 JArfield</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="/null"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Discuss on GitHub" href="/null"><i class="fas fa-comments"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="/null"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>